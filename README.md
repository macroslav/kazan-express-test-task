# Описание решения

## Изначальные идеи

Изначально планировал в решении использовать ruBERT для извлечения признаков из текстовых фичей (title и
short_description),
полученные вектора передавать в Catboost и иметь шикарное качество.

В процессе понял, что ~1200 классов для классификации и BERT - это очень медленно и не очень точно, к моему удивлению,
поэтому пришлось искать альтернативы

## Финальное решение

В финальном решении использовал:

+ Сделал очистку и обработку данных, попутно сократив число категорий с 1200 до ~600
+ CountVectorizer из sklearn для извлечения признаков из текстовых фичей
+ LogisticRegression для решения задачи классификации

## Результаты

```jupyter
train_f1_score = 0.91
valid_f1_score = 0.87
```

# Запуск

``` python3 run.py --save_model=VALUE ```

**VALUE** принимает значения true или false

Так же можно запустить ``` experiments.ipynb ```, в котором есть комментарии по **EDA**

# Что можно было бы улучшить или попробовать еще

1. Хотел попробовать дообучить ruBERT при помощи pyTorch, но вычислительно это довольно тяжело и долго, даже в колабе
2. Запустить Catboost на Tf-Idf, сталкивался с нехваткой памяти, поэтому использовал логрег
3. Так же пробовал unsupervised подход: считал эмбеддинги товаров по их описаниям, затем считал эмбеддинги всех
   уникальных деревьев категорий, искал по косинусной мере наиболее близкое дерево для каждого товара, была гипотеза,
   что ближайший эмбеддинг будет у настоящей категории товара, однако считалось очень долго + тест на маленькой выборке
   показал плохие результаты
